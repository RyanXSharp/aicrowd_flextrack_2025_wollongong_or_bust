{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook uses Daily Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predictions(true, predicted):\n",
    "    geometric_score = geometric_mean_score(\n",
    "        true,\n",
    "        predicted,\n",
    "        average=\"macro\",\n",
    "    )\n",
    "\n",
    "    # Calculate the f1 score\n",
    "    f1 = f1_score(\n",
    "        true,\n",
    "        predicted,\n",
    "        average=\"macro\",\n",
    "    )\n",
    "\n",
    "    precision = precision_score(\n",
    "        true, \n",
    "        predicted,\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    # print(f\"Geometric Mean Score: {geometric_score:.4f}\")\n",
    "    # print(f\"F1 Score: {f1:.4f}\")\n",
    "    # print(f\"Precision Score: {precision:.4f}\")\n",
    "\n",
    "    return geometric_score, f1, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_np_array(df, columns):\n",
    "    arr = np.stack(df[columns[0]].to_numpy())\n",
    "    for c in range(1,len(columns)):\n",
    "        arr = np.concatenate([arr,np.stack(df[columns[c]].to_numpy())],1)\n",
    "    return arr\n",
    "\n",
    "def parse_timestamp_list(s):\n",
    "    # find all datetime strings inside Timestamp('...')\n",
    "    matches = re.findall(r\"Timestamp\\('([^']+)'\\)\", s)\n",
    "    # convert each to pd.Timestamp\n",
    "    return [pd.to_datetime(m) for m in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sites_ABCD_NewFeatures.csv\", index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "working_hours = [10,11,12,13,14,15,16,17]\n",
    "\n",
    "df = df[(df[\"hour\"].isin(working_hours))].groupby([\"site\", \"date\"]).aggregate(list).sort_index().reset_index()\n",
    "\n",
    "minf = df['demand_response'].apply(min)\n",
    "maxf = df['demand_response'].apply(max)\n",
    "df[\"DayResponse\"] = np.where(\n",
    "    (minf==0) & (maxf==1),\n",
    "    1,\n",
    "    np.where(\n",
    "        (minf==-1) & (maxf==0),\n",
    "        -1,\n",
    "        np.where(\n",
    "            (minf==-1) & (maxf==1),\n",
    "            2,\n",
    "            0\n",
    "        )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df_ABCD = df.copy()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ABC_interval = pd.read_csv(\"../data/sites_ABC.csv\")[['Site', 'Timestamp_Local', 'Demand_Response_Flag']]\n",
    "df_DEF_interval = pd.read_csv(\"../data/sites_DEF.csv\")[['Site', 'Timestamp_Local', 'Demand_Response_Flag']]\n",
    "df_ABCD_interval = pd.concat([df_ABC_interval, df_DEF_interval[df_DEF_interval['Site']=='siteD']]).reset_index(drop=True)\n",
    "df_ABCD_interval['Timestamp_Local'] = pd.to_datetime(df_ABCD_interval['Timestamp_Local'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try One Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [ # - F1 | A: 0.6681 | B: 0.7033| C: 0.5943| D: 0.7796 | Mean: 0.6863\n",
    "  'temp_corr_dev', \n",
    "  'power_zscore_sh',\n",
    "  'power_zscore_sh_diff_t',\n",
    "  'power_zscore_sh_diff_wdt',\n",
    "  'power_zscore_sh_peek_diff',\n",
    "  'power_zscore_sh_diff',\n",
    "  'power_zscore_sh_peek_diff_t',\n",
    "  'power_zscore_sh_hourly_std',\n",
    "  'power_share_zscore_sh',\n",
    "  'power_share_zscore_sh_diff',\n",
    "  'power_share_zscore_sh_diff_t',\n",
    "  'power_share_zscore_sh_diff_wdt',\n",
    "  'power_share_zscore_sh_peek_diff',\n",
    "  'power_share_zscore_st_hourly_std'\n",
    "  ]\n",
    "\n",
    "site_col, all_feat_col, new_feat_col, val_cnts_col, geom_col, f1_col, pr_col = [], [], [], [], [], [], []\n",
    "\n",
    "combined_feats = base_features\n",
    "\n",
    "for site in ['A', 'B', 'C', 'D']:\n",
    "    \n",
    "    tr_ixs = df_ABCD['site']!=f\"site{site}\"\n",
    "    x_tr = get_np_array(df_ABCD.loc[tr_ixs], combined_feats)\n",
    "    y_tr = df_ABCD.loc[tr_ixs, 'DayResponse'].to_numpy() +1\n",
    "\n",
    "    x_te = get_np_array(df_ABCD.loc[~tr_ixs], combined_feats)\n",
    "\n",
    "    # Train & Predict\n",
    "    smote = SMOTE(random_state=94)\n",
    "    x_tr_bal, y_tr_bal = smote.fit_resample(x_tr, y_tr)\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(x_tr_bal,y_tr_bal)\n",
    "    preds = xgb.predict(x_te)\n",
    "\n",
    "    # Post Process\n",
    "    df_ABCD.loc[~tr_ixs, 'Pred'] = preds-1\n",
    "    df_ABCD.loc[(~tr_ixs) & df_ABCD[\"month\"].apply(lambda x: x[0]).isin([3,4,5,9,10,11]), 'Pred'] = 0 # No preds in shoulder seasons\n",
    "\n",
    "    # Map to Interval\n",
    "    neg1_start_ts = 9\n",
    "    pos1_start_ts = 9\n",
    "    pos2_start_ts = 2\n",
    "\n",
    "    df_ABCD['Pred_Interval'] = df_ABCD['Pred'].apply(\n",
    "        lambda x:\n",
    "        [0]*(neg1_start_ts-1) + [-1]*(32-neg1_start_ts+1) if x==-1 else\n",
    "        [0]*32 if x==0  else\n",
    "        [0]*(pos1_start_ts-1) + [1]*(32-pos1_start_ts+1) if x==1 else\n",
    "        [0]*(pos2_start_ts-1) + [1]*(8-pos2_start_ts+1) + [-1]*(24)\n",
    "    )\n",
    "\n",
    "    expanded_rows = []\n",
    "    for _, row in df_ABCD.loc[~tr_ixs].iterrows():\n",
    "        row_site = row['site']\n",
    "        row_ts = row['timestamp']\n",
    "        row_preds = row['Pred_Interval']\n",
    "        for ts, pred in zip(row_ts, row_preds):\n",
    "            expanded_rows.append({'Site':row_site, 'Timestamp_Local': ts, 'Pred_Interval': pred})\n",
    "\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "    expanded_df[\"Timestamp_Local\"] = pd.to_datetime(expanded_df[\"Timestamp_Local\"])\n",
    "    expanded_df['Site'] = f\"site{site}\"\n",
    "\n",
    "    df_ABCD_interval['Pred_Interval'] = 0\n",
    "    df_ABCD_interval = pd.merge(df_ABCD_interval[['Site', 'Timestamp_Local', 'Demand_Response_Flag']], expanded_df, how='outer', left_on=[\"Site\", \"Timestamp_Local\"], right_on=[\"Site\", \"Timestamp_Local\"]).fillna(0)\n",
    "\n",
    "    ixs_intvl = df_ABCD_interval['Site']==f\"site{site}\"\n",
    "\n",
    "    gm, f1, pr = eval_predictions(\n",
    "        true=df_ABCD_interval.loc[ixs_intvl,'Demand_Response_Flag'],\n",
    "        predicted=df_ABCD_interval.loc[ixs_intvl,'Pred_Interval']\n",
    "    )\n",
    "\n",
    "    site_col.append(f\"site{site}\")\n",
    "    all_feat_col.append(combined_feats)\n",
    "    # new_feat_col.append(new_feats)\n",
    "    val_cnts_col.append(df_ABCD.loc[~tr_ixs, 'Pred'].value_counts())\n",
    "    geom_col.append(gm)\n",
    "    f1_col.append(f1)\n",
    "    pr_col.append(pr)\n",
    "\n",
    "    if site=='D': print(f\"- F1 | A: {f1_col[-4]:.4f} | B: {f1_col[-3]:.4f}| C: {f1_col[-2]:.4f}| D: {f1_col[-1]:.4f} | Mean: {np.mean(f1_col[-4:]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Through Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature_cols = ['site','timestamp','demand_response','demand_response_capacity','date','busday','time','minute','hour','quarter_hour','week','working_hours']\n",
    "all_features = [col for col in df_ABCD.columns if col not in non_feature_cols + ['demand_response','demand_response_capacity','day_response', 'DayResponse','Pred','Pred_Interval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = ['temp_corr_dev', 'power_zscore_sh', 'power_zscore_sh_diff_t', 'power_zscore_sh_diff_wdt', 'power_zscore_sh_peek_diff', 'power_zscore_sh_diff', 'power_zscore_sh_peek_diff_t', 'power_zscore_sh_hourly_std', 'power_share_zscore_sh', 'power_share_zscore_sh_diff', 'power_share_zscore_sh_diff_t', 'power_share_zscore_sh_diff_wdt', 'power_share_zscore_sh_peek_diff', 'power_share_zscore_st_hourly_std', 'power_zscore_sh_peek4_diff', 'power_zscore_sh_lag4_diff', 'power_share_zscore_sh_peek4_diff', 'power_share_zscore_sh_lag4_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_features(df, df_interval, feature_list, target=\"DayResponse\", model=None):\n",
    "    df_ABCD = df.copy()\n",
    "    df_ABCD_interval = df_interval.copy()\n",
    "    geom_scores, f1_scores, pr_scores = [], [], []\n",
    "    for site in ['A', 'B', 'C', 'D']:\n",
    "        \n",
    "        tr_ixs = df_ABCD['site']!=f\"site{site}\"\n",
    "        x_tr = get_np_array(df_ABCD.loc[tr_ixs], feature_list)\n",
    "        y_tr = df_ABCD.loc[tr_ixs, 'DayResponse'].to_numpy() +1\n",
    "\n",
    "        x_te = get_np_array(df_ABCD.loc[~tr_ixs], feature_list)\n",
    "\n",
    "        # Train & Predict\n",
    "        smote = SMOTE(random_state=94)\n",
    "        x_tr_bal, y_tr_bal = smote.fit_resample(x_tr, y_tr)\n",
    "        model.fit(x_tr_bal,y_tr_bal)\n",
    "        preds = model.predict(x_te)\n",
    "\n",
    "        # Post Process\n",
    "        df_ABCD.loc[~tr_ixs, 'Pred'] = preds-1\n",
    "        df_ABCD.loc[(~tr_ixs) & df_ABCD[\"month\"].apply(lambda x: x[0]).isin([3,4,5,9,10,11]), 'Pred'] = 0 # No preds in shoulder seasons\n",
    "\n",
    "        # Map to Interval\n",
    "        neg1_start_ts = 9\n",
    "        pos1_start_ts = 9\n",
    "        pos2_start_ts = 2\n",
    "\n",
    "        df_ABCD['Pred_Interval'] = df_ABCD['Pred'].apply(\n",
    "            lambda x:\n",
    "            [0]*(neg1_start_ts-1) + [-1]*(32-neg1_start_ts+1) if x==-1 else\n",
    "            [0]*32 if x==0  else\n",
    "            [0]*(pos1_start_ts-1) + [1]*(32-pos1_start_ts+1) if x==1 else\n",
    "            [0]*(pos2_start_ts-1) + [1]*(8-pos2_start_ts+1) + [-1]*(24)\n",
    "        )\n",
    "\n",
    "        expanded_rows = []\n",
    "        for _, row in df_ABCD.loc[~tr_ixs].iterrows():\n",
    "            row_site = row['site']\n",
    "            row_ts = row['timestamp']\n",
    "            row_preds = row['Pred_Interval']\n",
    "            for ts, pred in zip(row_ts, row_preds):\n",
    "                expanded_rows.append({'Site':row_site, 'Timestamp_Local': ts, 'Pred_Interval': pred})\n",
    "\n",
    "        expanded_df = pd.DataFrame(expanded_rows)\n",
    "        expanded_df[\"Timestamp_Local\"] = pd.to_datetime(expanded_df[\"Timestamp_Local\"])\n",
    "        expanded_df['Site'] = f\"site{site}\"\n",
    "\n",
    "        df_ABCD_interval['Pred_Interval'] = 0\n",
    "        df_ABCD_interval = pd.merge(df_ABCD_interval[['Site', 'Timestamp_Local', 'Demand_Response_Flag']], expanded_df, how='outer', left_on=[\"Site\", \"Timestamp_Local\"], right_on=[\"Site\", \"Timestamp_Local\"]).fillna(0)\n",
    "\n",
    "        ixs_intvl = df_ABCD_interval['Site']==f\"site{site}\"\n",
    "\n",
    "        gm, f1, pr = eval_predictions(\n",
    "            true=df_ABCD_interval.loc[ixs_intvl,'Demand_Response_Flag'],\n",
    "            predicted=df_ABCD_interval.loc[ixs_intvl,'Pred_Interval']\n",
    "        )\n",
    "        geom_scores.append(gm)\n",
    "        f1_scores.append(f1)\n",
    "        pr_scores.append(pr)\n",
    "\n",
    "    return round(np.mean(geom_scores), 4), round(np.mean(f1_scores), 4), round(np.mean(pr_scores), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, df_interval, model, starting_features, features, target=\"DayResponse\"):\n",
    "    results = []\n",
    "\n",
    "    # Baseline with starting features\n",
    "    baseline_score = evaluate_features(df, df_interval, starting_features, target=target, model=model)[1]\n",
    "    print(f\"Baseline score: {baseline_score:.4f}\")\n",
    "\n",
    "    for feat in tqdm(features, desc=\"Testing features\", unit=\"feat\"):\n",
    "        if feat not in starting_features:\n",
    "            test_feats = starting_features + [feat]\n",
    "            # print(f\"Testing feature: {feat}\")\n",
    "\n",
    "            score = evaluate_features(df, df_interval, test_feats, target=target, model=model)[1]\n",
    "            improvement = score - baseline_score\n",
    "\n",
    "            results.append({\n",
    "                \"feature\": feat,\n",
    "                \"score\": score,\n",
    "                \"improvement\": improvement\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"improvement\",ascending=False)\n",
    "    return results_df\n",
    "\n",
    "def feature_ablation(df, df_interval, model, feature_list, dnt_list, target='DayResponse'):\n",
    "    results = []\n",
    "\n",
    "    # Baseline with all features\n",
    "    baseline_score = evaluate_features(df, df_interval, feature_list, target=target, model=model)[1]\n",
    "    print(f\"Baseline score: {baseline_score:.4f}\")\n",
    "\n",
    "    features_to_test = [f for f in feature_list if f not in dnt_list]\n",
    "    # Iterate by removing each feature once\n",
    "    for feat in tqdm(features_to_test, desc=\"Ablating features\", unit=\"feat\"):\n",
    "        reduced_feats = [f for f in feature_list if f != feat]\n",
    "        score = evaluate_features(df, df_interval, reduced_feats, target=target, model=model)[1]\n",
    "        change = score - baseline_score\n",
    "\n",
    "        results.append({\n",
    "            \"feature\": feat,\n",
    "            \"score\": score,\n",
    "            \"change_vs_full\": change\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"change_vs_full\",ascending=False)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = XGBClassifier(\n",
    "    random_state=42, \n",
    "    # n_estimators=100, \n",
    "    # learning_rate=0.05,\n",
    "    # subsample=0.8, \n",
    "    # colsample_bytree=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = ['temp_corr_dev', 'power_zscore_sh', 'power_zscore_sh_diff_t', 'power_zscore_sh_diff_wdt', 'power_zscore_sh_peek_diff', 'power_zscore_sh_diff', 'power_zscore_sh_peek_diff_t', 'power_zscore_sh_hourly_std', 'power_share_zscore_sh', 'power_share_zscore_sh_diff', 'power_share_zscore_sh_diff_t', 'power_share_zscore_sh_diff_wdt', 'power_share_zscore_sh_peek_diff', 'power_share_zscore_st_hourly_std', 'power_zscore_sh_peek4_diff', 'power_zscore_sh_lag4_diff', 'power_share_zscore_sh_peek4_diff', 'power_share_zscore_sh_lag4_diff', 'power_share_zscore_st_peek4_diff_t', 'season', 'month'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = evaluate_features(df_ABCD, df_ABCD_interval, base_features, target=\"DayResponse\", model=test_model)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features = ['power_zscore_st_lag4_diff', 'power_share_zscore_mt_peek_diff_t', 'power_share_std_st', 'power_zscore_st_lag4_diff_t', 'mean_usg_residual_zscore_mt_peek4_diff', 'mean_usg_residual_zscore_st_lag4_diff_t', 'irr_corr_dev', 'power_share_zscore_st_peek_diff', 'power_share_zscore_st_peek4_diff', 'mean_usg_residual', 'power_share_std_sh', 'mean_usg_residual_zscore_sh_lag_diff', 'power_share_mean_mt', 'power_zscore_mh_diff_t', 'mean_usg_residual_zscore_mh_peek4_diff_t', 'power_share_zscore_mh_hourly_std', 'mean_usg_residual_zscore_mt_lag4_diff', 'mean_usg_residual_mean_st', 'power_share_zscore_mh_peek_diff_t', 'power_zscore_sh_lag_diff', 'mean_usg_residual_zscore_sh_diff_t', 'mean_usg_residual_zscore_mt_peek4_diff_t', 'mean_usg_residual_mean_sh', 'power_share_zscore_mt_peek_diff', 'power_zscore_mt_lag4_diff', 'power_share_zscore_mh_lag4_diff', 'power_zscore_sh_peek4_diff_t', 'power_share_zscore_st_lag4_diff_t', 'power_zscore_mt_peek_diff_t', 'power_mean_mt', 'power_zscore_mt', 'mean_usg_residual_zscore_mh_hourly_std', 'power_zscore_mh', 'mean_usg_residual_std_sh', 'power_zscore_mt_hourly_std', 'power_zscore_mt_peek_diff', 'mean_usg_residual_zscore_mh_peek_diff_t', 'power_share_zscore_mh_lag4_diff_t', 'mean_usg_residual_zscore_mt', 'power_share_zscore_mh_peek4_diff_t', 'power_share_zscore_mh_peek_diff', 'power_share_zscore_mt_diff_t', 'mean_usg_residual_zscore_mh_lag4_diff_t', 'power_share_std_mh', 'mean_usg_residual_zscore_mt_diff_t', 'mean_usg_residual_zscore_sh_peek_diff_t', 'mean_usg_residual_zscore_mh_diff_wdt', 'power_share_zscore_mt_lag4_diff_t', 'power_share_std_mt', 'mean_usg_residual_mean_mt', 'day_of_week', 'power_zscore_mt_diff_t', 'mean_usg_residual_zscore_sh_peek4_diff', 'mean_usg_residual_zscore_st_diff_wdt', 'power_zscore_st_diff_wdt', 'power_share_zscore_sh_lag_diff', 'power_zscore_mh_peek_diff', 'power_share_zscore_mh_peek4_diff', 'power_share', 'mean_usg_residual_zscore_mh_diff', 'power_zscore_st_diff', 'mean_usg_residual_zscore_st_diff', 'mean_usg_residual_zscore_mh_lag_diff', 'mean_usg_residual_zscore_mh', 'power_share_mean_st', 'mean_usg_residual_zscore_st_lag4_diff', 'power_share_zscore_mt_diff', 'mean_usg_residual_mean_mh', 'power_share_zscore_mt_lag_diff_t', 'temp', 'power_zscore_st_peek_diff_t', 'mean_usg_residual_zscore_st_peek_diff_t', 'mean_usg_residual_zscore_mt_peek_diff', 'mean_usg_residual_zscore_sh_diff', 'power_share_zscore_st', 'mean_usg_residual_zscore_sh_peek4_diff_t', 'power_share_zscore_sh_hourly_std', 'power_zscore_mt_peek4_diff_t', 'power_share_zscore_sh_lag_diff_t', 'mean_usg_residual_std_mt', 'power_std_mt', 'power_share_zscore_mh_lag_diff', 'power_zscore_sh_lag4_diff_t', 'mean_usg_residual_zscore_sh_lag_diff_t', 'power_zscore_sh_lag_diff_t', 'power_std_st', 'mean_usg_residual_std_st', 'power_share_zscore_st_lag_diff_t', 'power_zscore_mh_lag4_diff_t', 'power_std_mh', 'power_share_zscore_mt_lag_diff', 'power_share_zscore_mh_diff_t', 'power_zscore_mh_peek4_diff_t', 'power_share_zscore_mh_lag_diff_t', 'week', 'mean_usg_residual_zscore_sh', 'power_zscore_mh_diff', 'mean_usg_residual_zscore_mt_lag_diff_t', 'power_zscore_mt_lag_diff_t', 'power_zscore_st', 'mean_usg_residual_zscore_st', 'power_mean_mh', 'power_mean_st', 'power_share_zscore_st_peek_diff_t', 'irr', 'irr_power_corr', 'power_std_sh', 'mean_usg_residual_std_mh', 'power_mean_sh', 'power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = feature_selection(df_ABCD, df_ABCD_interval, test_model, base_features, [f for f in all_features if f not in base_features + bad_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = base_features.copy()\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7641\n",
    "selected_features = ['temp_corr_dev', 'power_zscore_sh', 'power_zscore_sh_diff_t', 'power_zscore_sh_diff_wdt', 'power_zscore_sh_peek_diff', 'power_zscore_sh_diff', 'power_zscore_sh_peek_diff_t', 'power_zscore_sh_hourly_std', 'power_share_zscore_sh', 'power_share_zscore_sh_diff', 'power_share_zscore_sh_diff_t', 'power_share_zscore_sh_diff_wdt', 'power_share_zscore_sh_peek_diff', 'power_share_zscore_st_hourly_std', 'power_zscore_sh_peek4_diff', 'power_zscore_sh_lag4_diff', 'power_share_zscore_sh_peek4_diff', 'power_share_zscore_sh_lag4_diff', 'power_share_zscore_st_peek4_diff_t', 'season', 'month', 'power_share_zscore_sh_lag4_diff_t', 'power_share_zscore_mt_hourly_std', 'power_share_zscore_sh_peek4_diff_t', 'power_zscore_st_lag_diff_t', 'power_zscore_st_peek4_diff', 'mean_usg_residual_zscore_sh_diff_wdt', 'power_share_mean_sh', 'power_zscore_mh_peek_diff_t', 'mean_usg_residual_zscore_sh_lag4_diff', 'power_share_zscore_mh_diff', 'mean_usg_residual_zscore_mt_peek_diff_t', 'power_share_zscore_st_lag4_diff', 'mean_usg_residual_zscore_mt_diff', 'power_zscore_mh_lag_diff_t', 'power_share_mean_mh', 'mean_usg_residual_zscore_mh_peek_diff', 'power_zscore_st_peek_diff', 'power_zscore_mt_peek4_diff', 'mean_usg_residual_zscore_st_peek_diff'] \n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_features = feature_results[feature_results['improvement'] < -0.02]['feature'].to_list()\n",
    "# print(bad_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.7518\n",
    "while True:\n",
    "    feature_results = feature_selection(df_ABCD, df_ABCD_interval, test_model, selected_features, [f for f in all_features if f not in selected_features + bad_features])\n",
    "    new_ft = feature_results['feature'].iloc[0]\n",
    "    new_score = feature_results['score'].iloc[0]\n",
    "    score = new_score\n",
    "    selected_features = selected_features + [new_ft]\n",
    "    print(new_score, new_ft)\n",
    "    print(selected_features, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.7641\n",
    "while True:\n",
    "    feature_results = feature_ablation(df_ABCD, df_ABCD_interval, test_model, selected_features, dnt_list=[])\n",
    "    new_ft = feature_results['feature'].iloc[0]\n",
    "    new_score = feature_results['score'].iloc[0]\n",
    "    score = new_score\n",
    "    selected_features = [f for f in selected_features if f != new_ft]\n",
    "    print(new_score, new_ft)\n",
    "    print(selected_features, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
